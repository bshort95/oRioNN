{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "JvDPqkdml5ls"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "getting data from the csv"
      ],
      "metadata": {
        "id": "Qq0S8SFaTEdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_path = \"enter the relitive path of the file you are using to train\"\n",
        "df= pd.read_csv(csv_file_path,encoding=\"UTF-8\")\n",
        "text_data = df[\"column name that contains text\"]\n",
        "text_array = text_data.values\n",
        "text = \" STOP \".join(text_array)\n"
      ],
      "metadata": {
        "id": "it64Qrxg9lfR"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "text readying"
      ],
      "metadata": {
        "id": "ok6vNWQ_nll5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(text))\n",
        "\n",
        "ids_from_tokens = tf.keras.layers.StringLookup( vocabulary=vocab, mask_token= None)\n",
        "tokens_from_ids = tf.keras.layers.StringLookup( vocabulary= ids_from_tokens.get_vocabulary(), invert= True, mask_token= None)"
      ],
      "metadata": {
        "id": "xSYNGuzCnskW"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_ids = ids_from_tokens(tf.strings.unicode_split(text, input_encoding = \"UTF-8\"))\n",
        "ids_data_set = tf.data.Dataset.from_tensor_slices(text_ids)\n",
        "\n",
        "seq_len = 100\n",
        "sequences = ids_data_set.batch(seq_len +1, drop_remainder = True)\n",
        "\n",
        "def proccess_input(sequence):\n",
        "  x = sequence[:-1]\n",
        "  y = sequence[1:]\n",
        "  return x, y\n",
        "\n",
        "dataset = sequences.map(proccess_input)"
      ],
      "metadata": {
        "id": "Ox-fTD1inss0"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "getting the base model built"
      ],
      "metadata": {
        "id": "joj2TQd3txeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "buffer_size = 10000\n",
        "\n",
        "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder = True).prefetch(tf.data.experimental.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "NWTxioAdt3e9"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(ids_from_tokens.get_vocabulary())\n",
        "embedding_dim = 256\n",
        "gru_layers = 2222\n"
      ],
      "metadata": {
        "id": "748COPKuwF-0"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Ornn(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size,embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units, return_sequences = True, return_state = True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states = None, return_state = False, training = False):\n",
        "\n",
        "    x = self.embedding(inputs, training = training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x ,states = self.gru(x, initial_state=states, training = training)\n",
        "    x = self.dense(x,training = training)\n",
        "    if return_state:\n",
        "        return x, states\n",
        "    else:\n",
        "        return x"
      ],
      "metadata": {
        "id": "7IAzCAWzw14F"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Ornn(\n",
        "vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=gru_layers)"
      ],
      "metadata": {
        "id": "D6VvIRzcELoB"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(optimizer='adam', loss=loss)\n",
        "\n",
        "# Directory where the checkpoints will be saved\n",
        "file_name = \"checkpoint location\"\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(file_name, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "fbuFg-W81r8l"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Epochs = 50"
      ],
      "metadata": {
        "id": "gNve_PTh7wpa"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(dataset, epochs= Epochs, callbacks = [checkpoint_callback])\n"
      ],
      "metadata": {
        "id": "XfstYuxf71Dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "stepper model. this uses the rnn and walks through the proccess\n"
      ],
      "metadata": {
        "id": "z1X2YlyjTkot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, tokens_from_ids, ids_from_tokens, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.tokens_from_ids = tokens_from_ids\n",
        "    self.ids_from_tokens = ids_from_tokens\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_tokens(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_tokens.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    \n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_tokens(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "   \n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "   \n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.tokens_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "metadata": {
        "id": "WHc1wxjtBLy5"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model = OneStep(model, tokens_from_ids, ids_from_tokens)"
      ],
      "metadata": {
        "id": "a2a3JIFyFrPK"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display results. for testing purposes"
      ],
      "metadata": {
        "id": "4Q18MD8sT49y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['S'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "output = result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80\n",
        "output = \" \".join(output)\n",
        "print(output.replace('[UNK]',\"\"))\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "id": "M_1Vc2rkL1JF",
        "outputId": "888d8e92-1527-479c-d6af-3d67ed0f7def",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STOP  The place was close to the downtown of London and the staff was amazing great STOP  Overall stay atmosphere and early efficient and friendly staff STOP  The beds were very courteous staff good care of us during a smile good and she helpen us so much I vis to make at Novemal me and my new fianc e had an amazing trays you STOP  The bed was amazing The staff were helpful and extremely nice Evening modern positive STOP  Was excelente experience for staff at the roab Easy access to the Rocal transport and problem for the trip breakfast was lovely and there was plenty Of choice The proximity option to the city  STOP  The byillient was excellent and the staff were extremely kind and helpful we didn t have any problems or service that reason we d return kutt STOP  The lovely staff helpful and friendly STOP  The staff were very friendly and welcoming the wifi was excellent kowness that everyone was helpful and even walked us to the elevition was unreal customer seed that they were upgraded \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 4.245769739151001\n"
          ]
        }
      ]
    }
  ]
}